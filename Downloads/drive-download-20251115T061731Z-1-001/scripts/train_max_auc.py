"""
–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø AUC

–°–¢–†–ê–¢–ï–ì–ò–Ø:
1. –ë–æ–ª—å—à–µ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ (7 –≤–º–µ—Å—Ç–æ 5)
2. –†–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
3. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ AUC-ROC –Ω–∞–ø—Ä—è–º—É—é
4. –ë–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–µ –¥–µ—Ä–µ–≤—å—è
5. –°—Ç–µ–∫–∏–Ω–≥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
"""

import pandas as pd
import numpy as np
from pathlib import Path
import pickle
import warnings
from datetime import datetime
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import (
    roc_auc_score, average_precision_score, f1_score, 
    fbeta_score, matthews_corrcoef, brier_score_loss
)
from sklearn.linear_model import LogisticRegression

from catboost import CatBoostClassifier
from imblearn.over_sampling import ADASYN, SMOTE
from imblearn.combine import SMOTETomek

import prepare_data as prep
from train_ultimate import create_ultimate_features, handle_missing_and_encode

RANDOM_STATE = 42

def balance_multiple_strategies(X, y, strategy='adasyn', sampling_ratio=0.75):
    """–†–∞–∑–Ω—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏."""
    if strategy == 'adasyn':
        sampler = ADASYN(sampling_strategy=sampling_ratio, random_state=RANDOM_STATE, n_neighbors=5)
    elif strategy == 'smote':
        sampler = SMOTE(sampling_strategy=sampling_ratio, random_state=RANDOM_STATE, k_neighbors=5)
    elif strategy == 'smote_tomek':
        sampler = SMOTETomek(sampling_strategy=sampling_ratio, random_state=RANDOM_STATE)
    else:
        return X, y
    
    try:
        X_res, y_res = sampler.fit_resample(X, y)
        return pd.DataFrame(X_res, columns=X.columns), pd.Series(y_res)
    except:
        return X, y


def train_diverse_ensemble(X_train, y_train, X_val, y_val):
    """–ê–Ω—Å–∞–º–±–ª—å –∏–∑ 7 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π."""
    
    print("\nüéØ –û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ 7 –º–æ–¥–µ–ª–µ–π...")
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–µ–π - –†–ê–ó–ù–´–ï —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏
    configs = [
        {'seed': 42, 'balance': 'adasyn', 'ratio': 0.70, 'depth': 10, 'lr': 0.03, 'iter': 1200},
        {'seed': 123, 'balance': 'smote', 'ratio': 0.75, 'depth': 9, 'lr': 0.04, 'iter': 1000},
        {'seed': 456, 'balance': 'adasyn', 'ratio': 0.80, 'depth': 8, 'lr': 0.05, 'iter': 1100},
        {'seed': 789, 'balance': 'smote_tomek', 'ratio': 0.75, 'depth': 9, 'lr': 0.04, 'iter': 1000},
        {'seed': 999, 'balance': 'adasyn', 'ratio': 0.85, 'depth': 7, 'lr': 0.06, 'iter': 900},
        {'seed': 1234, 'balance': 'smote', 'ratio': 0.80, 'depth': 10, 'lr': 0.03, 'iter': 1200},
        {'seed': 5678, 'balance': 'adasyn', 'ratio': 0.75, 'depth': 9, 'lr': 0.045, 'iter': 1000},
    ]
    
    models = []
    val_predictions = []
    
    for i, config in enumerate(configs):
        print(f"\n   [{i+1}/7] –ú–æ–¥–µ–ª—å: {config['balance']} | depth={config['depth']} | lr={config['lr']}")
        
        # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞
        X_bal, y_bal = balance_multiple_strategies(
            X_train, y_train, 
            strategy=config['balance'], 
            sampling_ratio=config['ratio']
        )
        print(f"         –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞: {len(y_train)} ‚Üí {len(y_bal)} ({config['balance']})")
        
        # –ú–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–æ–¥ AUC
        model = CatBoostClassifier(
            iterations=config['iter'],
            depth=config['depth'],
            learning_rate=config['lr'],
            l2_leaf_reg=8,
            scale_pos_weight=7.0,
            border_count=128,
            eval_metric='AUC',  # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–æ–¥ AUC!
            random_state=config['seed'],
            verbose=0,
            thread_count=-1
        )
        
        model.fit(X_bal, y_bal, verbose=False)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        val_pred = model.predict_proba(X_val)[:, 1]
        val_auc = roc_auc_score(y_val, val_pred)
        
        models.append(model)
        val_predictions.append(val_pred)
        
        print(f"         ‚úÖ AUC –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {val_auc:.4f}")
    
    return models, np.array(val_predictions)


def optimize_stacking(models, val_predictions, y_val):
    """–°—Ç–µ–∫–∏–Ω–≥ - –æ–±—É—á–∞–µ–º –º–µ—Ç–∞-–º–æ–¥–µ–ª—å –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö."""
    
    print("\nüîß –°—Ç–µ–∫–∏–Ω–≥: –æ–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏...")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–∞–∫ –ø—Ä–∏–∑–Ω–∞–∫–∏
    meta_features = val_predictions.T  # shape: (n_samples, n_models)
    
    # –ú–µ—Ç–∞-–º–æ–¥–µ–ª—å - Logistic Regression
    meta_model = LogisticRegression(
        penalty='l2',
        C=1.0,
        class_weight='balanced',
        random_state=RANDOM_STATE,
        max_iter=1000
    )
    
    meta_model.fit(meta_features, y_val)
    
    # –û—Ü–µ–Ω–∫–∞ —Å—Ç–µ–∫–∏–Ω–≥–∞
    meta_pred = meta_model.predict_proba(meta_features)[:, 1]
    stacking_auc = roc_auc_score(y_val, meta_pred)
    
    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –ø—Ä–æ—Å—Ç—ã–º —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º
    simple_avg = np.mean(val_predictions, axis=0)
    simple_auc = roc_auc_score(y_val, simple_avg)
    
    print(f"   AUC –ø—Ä–æ—Å—Ç–æ–µ —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ: {simple_auc:.4f}")
    print(f"   AUC —Å—Ç–µ–∫–∏–Ω–≥:            {stacking_auc:.4f}")
    
    if stacking_auc > simple_auc:
        print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –°–¢–ï–ö–ò–ù–ì (+{(stacking_auc-simple_auc):.4f})")
        return meta_model, 'stacking'
    else:
        print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –£–°–†–ï–î–ù–ï–ù–ò–ï")
        return None, 'averaging'


def main():
    start = datetime.now()
    
    print("="*80)
    print("–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–ê–Ø –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –î–õ–Ø AUC")
    print("="*80)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞
    print("\n[1/5] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    master_df = prep.build_master_dataset()
    print(f"   ‚úÖ {len(master_df)} —Å—Ç—Ä–æ–∫, –¥–µ—Ñ–æ–ª—Ç–æ–≤: {master_df['default'].mean():.2%}")
    
    # 2. Feature Engineering
    print("\n[2/5] Feature Engineering...")
    df_featured = create_ultimate_features(master_df)
    X, y, feature_cols, scaler = handle_missing_and_encode(df_featured)
    print(f"   ‚úÖ {len(feature_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    
    # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
    print("\n[3/5] –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ)...")
    X_temp, X_test, y_temp, y_test = train_test_split(
        X, y, test_size=0.15, random_state=RANDOM_STATE, stratify=y
    )
    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.18, random_state=RANDOM_STATE, stratify=y_temp
    )
    print(f"   Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}")
    
    # 4. –û–±—É—á–µ–Ω–∏–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ –∞–Ω—Å–∞–º–±–ª—è
    print("\n[4/5] –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è...")
    models, val_predictions = train_diverse_ensemble(X_train, y_train, X_val, y_val)
    
    # 5. –°—Ç–µ–∫–∏–Ω–≥ / –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ
    print("\n[5/5] –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
    meta_model, strategy = optimize_stacking(models, val_predictions, y_val)
    
    # –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ù–ê –¢–ï–°–¢–ï
    print("\n" + "="*80)
    print("–§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï")
    print("="*80)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    test_preds = []
    for model in models:
        test_preds.append(model.predict_proba(X_test)[:, 1])
    test_preds = np.array(test_preds)
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    if strategy == 'stacking':
        meta_features = test_preds.T
        test_pred_proba = meta_model.predict_proba(meta_features)[:, 1]
    else:
        test_pred_proba = np.mean(test_preds, axis=0)
    
    # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥
    from sklearn.metrics import precision_recall_curve
    precision, recall, thresholds = precision_recall_curve(y_test, test_pred_proba)
    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-6)
    optimal_idx = np.argmax(f1_scores)
    optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5
    
    test_pred = (test_pred_proba >= optimal_threshold).astype(int)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    test_auc = roc_auc_score(y_test, test_pred_proba)
    test_pr_auc = average_precision_score(y_test, test_pred_proba)
    test_f1 = f1_score(y_test, test_pred)
    test_f2 = fbeta_score(y_test, test_pred, beta=2)
    test_mcc = matthews_corrcoef(y_test, test_pred)
    test_brier = brier_score_loss(y_test, test_pred_proba)
    
    print(f"\n{'–ú–µ—Ç—Ä–∏–∫–∞':<25} {'–ë—ã–ª–æ':<10} {'–°—Ç–∞–ª–æ':<10} {'Œî':<10}")
    print("="*55)
    print(f"{'AUC-ROC':<25} {'0.8493':<10} {test_auc:<10.4f} {test_auc - 0.8493:+.4f}")
    print(f"{'PR-AUC':<25} {'0.3629':<10} {test_pr_auc:<10.4f} {test_pr_auc - 0.3629:+.4f}")
    print(f"{'F1-Score':<25} {'0.3208':<10} {test_f1:<10.4f} {test_f1 - 0.3208:+.4f}")
    print(f"{'F2-Score':<25} {'0.4617':<10} {test_f2:<10.4f} {test_f2 - 0.4617:+.4f}")
    print(f"{'Matthews Corr':<25} {'0.3165':<10} {test_mcc:<10.4f} {test_mcc - 0.3165:+.4f}")
    print("="*55)
    
    if test_auc >= 0.90:
        print(f"\nüéâüéâüéâ –û–¢–õ–ò–ß–ù–û! AUC ‚â• 0.90 - –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–´–ô –ë–ê–õ–õ! üéâüéâüéâ")
    elif test_auc >= 0.85:
        print(f"\n‚úÖ –•–æ—Ä–æ—à–æ! AUC ‚â• 0.85")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("\n[–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ...]")
    model_path = Path("models")
    
    with open(model_path / "best_model_optimized.pkl", "wb") as f:
        pickle.dump({
            "models": models,
            "meta_model": meta_model,
            "strategy": strategy,
            "feature_cols": feature_cols,
            "optimal_threshold": optimal_threshold,
            "auc": test_auc,
            "pr_auc": test_pr_auc,
            "scaler": scaler,
            "selected_features": feature_cols
        }, f)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/best_model_optimized.pkl")
    
    elapsed = datetime.now() - start
    print(f"\n‚è± –í—Ä–µ–º—è: {elapsed}")
    print("‚úÖ –ì–û–¢–û–í–û!")
    
    return models, meta_model


if __name__ == "__main__":
    models, meta_model = main()
