"""
ML Pipeline –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–µ—Ñ–æ–ª—Ç–∞ –∑–∞–µ–º—â–∏–∫–∞.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ
2. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø—Ä–æ–ø—É—Å–∫–∏ –∏ –≤—ã–±—Ä–æ—Å—ã
3. –°–æ–∑–¥–∞–µ—Ç —Ñ–∏—á–∏
4. –û–±—É—á–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π —Å –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
5. –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ (AUC, PR-AUC)
6. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
"""

import pandas as pd
import numpy as np
from pathlib import Path
import pickle
from typing import Tuple
import warnings
warnings.filterwarnings('ignore')

# ML –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    roc_auc_score, 
    average_precision_score, 
    classification_report,
    confusion_matrix
)
from imblearn.over_sampling import SMOTE

# Gradient Boosting
try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except (ImportError, Exception) as e:
    XGBOOST_AVAILABLE = False
    print(f"‚ö† XGBoost –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º: {type(e).__name__}")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except (ImportError, Exception) as e:
    LIGHTGBM_AVAILABLE = False
    print(f"‚ö† LightGBM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º: {type(e).__name__}")

try:
    from catboost import CatBoostClassifier
    CATBOOST_AVAILABLE = True
except (ImportError, Exception) as e:
    CATBOOST_AVAILABLE = False
    print(f"‚ö† CatBoost –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º: {type(e).__name__}")

import prepare_data as prep


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

BASE_PATH = Path("data_sets")
RANDOM_STATE = 42
N_SPLITS = 5  # –¥–ª—è StratifiedKFold

# –ö–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∏—Å–∫–ª—é—á–∞–µ–º –∏–∑ –æ–±—É—á–µ–Ω–∏—è
EXCLUDE_COLS = ["customer_id", "default"]


# ============================================================================
# –§–£–ù–ö–¶–ò–ò –ü–û–î–ì–û–¢–û–í–ö–ò –î–ê–ù–ù–´–•
# ============================================================================

def handle_missing_values(df: pd.DataFrame, target_col: str = "default") -> pd.DataFrame:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤:
    - –ß–∏—Å–ª–æ–≤—ã–µ: –º–µ–¥–∏–∞–Ω–∞
    - –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: –º–æ–¥–∞ –∏–ª–∏ "unknown"
    """
    df = df.copy()
    
    for col in df.columns:
        if col in EXCLUDE_COLS:
            continue
            
        if df[col].isna().sum() == 0:
            continue
            
        if pd.api.types.is_numeric_dtype(df[col]):
            # –ß–∏—Å–ª–æ–≤—ã–µ: –º–µ–¥–∏–∞–Ω–∞
            median_val = df[col].median()
            if pd.isna(median_val):
                median_val = 0
            df[col] = df[col].fillna(median_val)
        else:
            # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: –º–æ–¥–∞ –∏–ª–∏ "unknown"
            mode_val = df[col].mode()
            if len(mode_val) > 0:
                df[col] = df[col].fillna(mode_val[0])
            else:
                df[col] = df[col].fillna("unknown")
    
    return df


def encode_categorical_features(df: pd.DataFrame) -> Tuple[pd.DataFrame, dict]:
    """
    –ö–æ–¥–∏—Ä—É–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:
    - Label Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
    - –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏ —Å–ª–æ–≤–∞—Ä—å —ç–Ω–∫–æ–¥–µ—Ä–æ–≤
    """
    df = df.copy()
    encoders = {}
    
    for col in df.columns:
        if col in EXCLUDE_COLS:
            continue
            
        if df[col].dtype == "object" or df[col].dtype.name == "category":
            le = LabelEncoder()
            # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –ø–µ—Ä–µ–¥ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
            df[col] = df[col].fillna("unknown")
            df[col] = le.fit_transform(df[col].astype(str))
            encoders[col] = le
    
    return df, encoders


def create_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏—á–∏ (feature engineering).
    """
    df = df.copy()
    
    # –ü—Ä–∏–º–µ—Ä—ã —Ñ–∏—á–µ–π (–¥–æ–±–∞–≤—å —Å–≤–æ–∏ –ø–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏):
    
    # 1. –î–æ–ª–≥–æ–≤–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–æ—Ö–æ–¥ –∏ –¥–æ–ª–≥)
    if "monthly_income" in df.columns and "total_monthly_debt_payment" in df.columns:
        df["debt_to_income_ratio"] = (
            df["total_monthly_debt_payment"] / (df["monthly_income"] + 1e-6)
        )
    
    # 2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫—Ä–µ–¥–∏—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if "credit_usage_amount" in df.columns and "available_credit" in df.columns:
        df["credit_utilization"] = (
            df["credit_usage_amount"] / (df["available_credit"] + df["credit_usage_amount"] + 1e-6)
        )
    
    # 3. –°–≤–æ–±–æ–¥–Ω—ã–π –¥–µ–Ω–µ–∂–Ω—ã–π –ø–æ—Ç–æ–∫ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –¥–æ—Ö–æ–¥–∞
    if "monthly_free_cash_flow" in df.columns and "monthly_income" in df.columns:
        df["cash_flow_ratio"] = (
            df["monthly_free_cash_flow"] / (df["monthly_income"] + 1e-6)
        )
    
    # 4. –í–æ–∑—Ä–∞—Å—Ç –∏ —Å—Ç–∞–∂ —Ä–∞–±–æ—Ç—ã
    if "age" in df.columns and "employment_length" in df.columns:
        df["employment_to_age_ratio"] = (
            df["employment_length"] / (df["age"] + 1e-6)
        )
    
    return df


def prepare_features(df: pd.DataFrame, target_col: str = "default") -> Tuple[pd.DataFrame, pd.Series, list]:
    """
    –ü–æ–ª–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π:
    1. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    2. Feature engineering
    3. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
    4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ X –∏ y
    """
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    df = handle_missing_values(df, target_col)
    
    # Feature engineering
    df = create_features(df)
    
    # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
    df, encoders = encode_categorical_features(df)
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    feature_cols = [c for c in df.columns if c not in EXCLUDE_COLS]
    X = df[feature_cols].copy()
    y = df[target_col].copy()
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ
    for col in X.columns:
        if not pd.api.types.is_numeric_dtype(X[col]):
            X[col] = pd.to_numeric(X[col], errors="coerce").fillna(0)
    
    return X, y, feature_cols


# ============================================================================
# –ú–û–î–ï–õ–ò
# ============================================================================

def train_logistic_regression(X_train: pd.DataFrame, y_train: pd.Series, 
                               X_test: pd.DataFrame, y_test: pd.Series):
    """–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤."""
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # –ú–æ–¥–µ–ª—å —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π
    model = LogisticRegression(
        class_weight="balanced",
        random_state=RANDOM_STATE,
        max_iter=1000,
        solver="lbfgs"
    )
    
    model.fit(X_train_scaled, y_train)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    y_pred = model.predict(X_test_scaled)
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    auc = roc_auc_score(y_test, y_pred_proba)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    return {
        "model": model,
        "scaler": scaler,
        "auc": auc,
        "pr_auc": pr_auc,
        "y_pred_proba": y_pred_proba,
        "y_pred": y_pred,
        "name": "Logistic Regression"
    }


def train_random_forest(X_train: pd.DataFrame, y_train: pd.Series,
                        X_test: pd.DataFrame, y_test: pd.Series):
    """Random Forest —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤."""
    model = RandomForestClassifier(
        n_estimators=200,
        max_depth=15,
        min_samples_split=10,
        min_samples_leaf=5,
        class_weight="balanced",
        random_state=RANDOM_STATE,
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    
    auc = roc_auc_score(y_test, y_pred_proba)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    return {
        "model": model,
        "scaler": None,
        "auc": auc,
        "pr_auc": pr_auc,
        "y_pred_proba": y_pred_proba,
        "y_pred": y_pred,
        "name": "Random Forest"
    }


def train_xgboost(X_train: pd.DataFrame, y_train: pd.Series,
                  X_test: pd.DataFrame, y_test: pd.Series):
    """XGBoost —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤."""
    if not XGBOOST_AVAILABLE:
        return None
    
    # –í—ã—á–∏—Å–ª—è–µ–º scale_pos_weight –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        scale_pos_weight=scale_pos_weight,
        random_state=RANDOM_STATE,
        eval_metric="logloss",
        n_jobs=-1
    )
    
    model.fit(X_train, y_train)
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    
    auc = roc_auc_score(y_test, y_pred_proba)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    return {
        "model": model,
        "scaler": None,
        "auc": auc,
        "pr_auc": pr_auc,
        "y_pred_proba": y_pred_proba,
        "y_pred": y_pred,
        "name": "XGBoost"
    }


def train_lightgbm(X_train: pd.DataFrame, y_train: pd.Series,
                   X_test: pd.DataFrame, y_test: pd.Series):
    """LightGBM —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤."""
    if not LIGHTGBM_AVAILABLE:
        return None
    
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    model = lgb.LGBMClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        scale_pos_weight=scale_pos_weight,
        random_state=RANDOM_STATE,
        n_jobs=-1,
        verbose=-1
    )
    
    model.fit(X_train, y_train)
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    
    auc = roc_auc_score(y_test, y_pred_proba)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    return {
        "model": model,
        "scaler": None,
        "auc": auc,
        "pr_auc": pr_auc,
        "y_pred_proba": y_pred_proba,
        "y_pred": y_pred,
        "name": "LightGBM"
    }


def train_catboost(X_train: pd.DataFrame, y_train: pd.Series,
                   X_test: pd.DataFrame, y_test: pd.Series):
    """CatBoost —Å –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–æ–π –∫–ª–∞—Å—Å–æ–≤."""
    if not CATBOOST_AVAILABLE:
        return None
    
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    
    model = CatBoostClassifier(
        iterations=200,
        depth=6,
        learning_rate=0.1,
        scale_pos_weight=scale_pos_weight,
        random_state=RANDOM_STATE,
        verbose=False
    )
    
    model.fit(X_train, y_train)
    
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    y_pred = model.predict(X_test)
    
    auc = roc_auc_score(y_test, y_pred_proba)
    pr_auc = average_precision_score(y_test, y_pred_proba)
    
    return {
        "model": model,
        "scaler": None,
        "auc": auc,
        "pr_auc": pr_auc,
        "y_pred_proba": y_pred_proba,
        "y_pred": y_pred,
        "name": "CatBoost"
    }


# ============================================================================
# –ö–†–û–°–°-–í–ê–õ–ò–î–ê–¶–ò–Ø
# ============================================================================

def cross_validate_model(model_func, X: pd.DataFrame, y: pd.Series, 
                        cv_splits: int = N_SPLITS):
    """
    –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏.
    """
    skf = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=RANDOM_STATE)
    
    auc_scores = []
    pr_auc_scores = []
    
    for train_idx, val_idx in skf.split(X, y):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        
        result = model_func(X_train, y_train, X_val, y_val)
        if result:
            auc_scores.append(result["auc"])
            pr_auc_scores.append(result["pr_auc"])
    
    return {
        "auc_mean": np.mean(auc_scores),
        "auc_std": np.std(auc_scores),
        "pr_auc_mean": np.mean(pr_auc_scores),
        "pr_auc_std": np.std(pr_auc_scores),
        "auc_scores": auc_scores,
        "pr_auc_scores": pr_auc_scores
    }


# ============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    print("=" * 80)
    print("ML PIPELINE: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–µ—Ñ–æ–ª—Ç–∞ –∑–∞–µ–º—â–∏–∫–∞")
    print("=" * 80)
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\n[1/6] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    master_df = prep.build_master_dataset()
    print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {master_df.shape[0]} —Å—Ç—Ä–æ–∫, {master_df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∞—Ä–≥–µ—Ç–∞
    if "default" not in master_df.columns:
        raise ValueError("‚ùå –ö–æ–ª–æ–Ω–∫–∞ 'default' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    
    print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∞—Ä–≥–µ—Ç–∞:")
    print(f"   {master_df['default'].value_counts().to_dict()}")
    print(f"   –î–æ–ª—è –¥–µ—Ñ–æ–ª—Ç–æ–≤: {master_df['default'].mean():.2%}")
    
    # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π
    print("\n[2/6] –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∏—á–µ–π...")
    X, y, feature_cols = prepare_features(master_df)
    print(f"   ‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(feature_cols)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print(f"   –ü—Ä–æ–ø—É—Å–∫–∏ –≤ X: {X.isna().sum().sum()}")
    
    # 3. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    print("\n[3/6] –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test...")
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )
    print(f"   Train: {X_train.shape[0]} —Å—Ç—Ä–æ–∫")
    print(f"   Test: {X_test.shape[0]} —Å—Ç—Ä–æ–∫")
    
    # 4. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("\n[4/6] –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    models = []
    
    # Logistic Regression
    print("   üöÄ –û–±—É—á–µ–Ω–∏–µ Logistic Regression...")
    try:
        lr_result = train_logistic_regression(X_train, y_train, X_test, y_test)
        if lr_result:
            models.append(lr_result)
            print(f"      ‚úÖ AUC: {lr_result['auc']:.4f}, PR-AUC: {lr_result['pr_auc']:.4f}")
    except Exception as e:
        print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # Random Forest
    print("   üöÄ –û–±—É—á–µ–Ω–∏–µ Random Forest...")
    try:
        rf_result = train_random_forest(X_train, y_train, X_test, y_test)
        if rf_result:
            models.append(rf_result)
            print(f"      ‚úÖ AUC: {rf_result['auc']:.4f}, PR-AUC: {rf_result['pr_auc']:.4f}")
    except Exception as e:
        print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # XGBoost
    if XGBOOST_AVAILABLE:
        print("   üöÄ –û–±—É—á–µ–Ω–∏–µ XGBoost...")
        try:
            xgb_result = train_xgboost(X_train, y_train, X_test, y_test)
            if xgb_result:
                models.append(xgb_result)
                print(f"      ‚úÖ AUC: {xgb_result['auc']:.4f}, PR-AUC: {xgb_result['pr_auc']:.4f}")
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # LightGBM
    if LIGHTGBM_AVAILABLE:
        print("   üöÄ –û–±—É—á–µ–Ω–∏–µ LightGBM...")
        try:
            lgb_result = train_lightgbm(X_train, y_train, X_test, y_test)
            if lgb_result:
                models.append(lgb_result)
                print(f"      ‚úÖ AUC: {lgb_result['auc']:.4f}, PR-AUC: {lgb_result['pr_auc']:.4f}")
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    # CatBoost
    if CATBOOST_AVAILABLE:
        print("   üöÄ –û–±—É—á–µ–Ω–∏–µ CatBoost...")
        try:
            cb_result = train_catboost(X_train, y_train, X_test, y_test)
            if cb_result:
                models.append(cb_result)
                print(f"      ‚úÖ AUC: {cb_result['auc']:.4f}, PR-AUC: {cb_result['pr_auc']:.4f}")
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
    
    if not models:
        raise ValueError("‚ùå –ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞!")
    
    # 5. –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    print("\n[5/6] –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    print("\n" + "=" * 80)
    print(f"{'–ú–æ–¥–µ–ª—å':<20} {'AUC':<10} {'PR-AUC':<10}")
    print("=" * 80)
    
    for model_result in models:
        print(f"{model_result['name']:<20} {model_result['auc']:<10.4f} {model_result['pr_auc']:<10.4f}")
    
    # –õ—É—á—à–∞—è –ø–æ PR-AUC (–≤–∞–∂–Ω–µ–µ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    best_model = max(models, key=lambda x: x['pr_auc'])
    print("\n" + "=" * 80)
    print(f"üèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model['name']}")
    print(f"   AUC: {best_model['auc']:.4f}")
    print(f"   PR-AUC: {best_model['pr_auc']:.4f}")
    print("=" * 80)
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    print("\n[6/6] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
    model_path = Path("models")
    model_path.mkdir(exist_ok=True)
    
    with open(model_path / "best_model.pkl", "wb") as f:
        pickle.dump({
            "model": best_model["model"],
            "scaler": best_model["scaler"],
            "feature_cols": feature_cols,
            "model_name": best_model["name"],
            "auc": best_model["auc"],
            "pr_auc": best_model["pr_auc"]
        }, f)
    
    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/best_model.pkl")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    results_df = pd.DataFrame([
        {
            "model": m["name"],
            "auc": m["auc"],
            "pr_auc": m["pr_auc"]
        }
        for m in models
    ])
    results_df.to_csv("models/model_comparison.csv", index=False)
    print(f"   ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π: models/model_comparison.csv")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    predictions_df = pd.DataFrame({
        "y_true": y_test.values,
        "y_pred": best_model["y_pred"],
        "y_pred_proba": best_model["y_pred_proba"]
    })
    predictions_df.to_csv("models/predictions.csv", index=False)
    print(f"   ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: models/predictions.csv")
    
    print("\n" + "=" * 80)
    print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 80)
    
    return best_model, models, X_test, y_test, feature_cols


if __name__ == "__main__":
    best_model, all_models, X_test, y_test, feature_cols = main()

